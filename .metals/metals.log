2023.10.23 15:44:20 INFO  Started: Metals version 1.1.0 in folders '/home/zia/spark-scala' for client Visual Studio Code 1.83.1.
2023.10.23 15:44:21 WARN  Build server is not auto-connectable.
2023.10.23 15:44:21 WARN  no build target for: /home/zia/spark-scala/build.sbt
2023.10.23 15:44:31 INFO  no build target found for /home/zia/spark-scala/build.sbt. Using presentation compiler with project's scala-library version: 3.3.1
2023.10.23 15:44:38 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 15:44:45 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 15:44:46 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
Oct 23, 2023 3:44:47 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 25
2023.10.23 15:44:47 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 15:44:47 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 15:44:54 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 15:44:54 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 15:44:55 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 15:44:55 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 15:46:11 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 15:46:12 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 15:46:12 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 15:46:13 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 15:46:13 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 15:46:15 WARN  no build target for: /home/zia/spark-scala/build.sbt
2023.10.23 15:46:15 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 15:46:15 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 15:46:25 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 15:46:27 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 15:49:45 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 15:49:46 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 15:49:50 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 15:49:55 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 15:49:55 WARN  no build target for: /home/zia/spark-scala/build.sbt
2023.10.23 15:49:55 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 15:49:56 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 15:52:24 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 15:53:57 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 15:53:59 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 15:54:01 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 15:54:14 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 15:54:16 WARN  no build target for: /home/zia/spark-scala/build.sbt
2023.10.23 15:54:16 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 15:54:16 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 15:57:12 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 15:57:20 WARN  no build target for: /home/zia/spark-scala/build.sbt
2023.10.23 15:57:20 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 15:57:20 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 15:57:44 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 15:57:45 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 15:58:06 WARN  no build target for: /home/zia/spark-scala/build.sbt
2023.10.23 15:58:06 INFO  skipping build import with status 'Dismissed'
2023.10.23 15:58:06 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 15:58:06 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 17:39:07 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.23 17:39:22 INFO  time: code lens generation in 1.56s
2023.10.23 17:50:37 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 17:50:39 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 17:50:40 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 17:50:40 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 17:50:41 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 17:50:42 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 17:50:43 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 17:59:39 WARN  no build target for: /home/zia/spark-scala/build.sbt
2023.10.23 17:59:39 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 17:59:39 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 19:13:08 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 19:13:09 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 19:13:10 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 19:13:11 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 19:13:11 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 19:13:14 WARN  no build target for: /home/zia/spark-scala/build.sbt
2023.10.23 19:13:14 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 19:13:14 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 19:23:22 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 19:23:23 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 19:23:24 WARN  no build target for: /home/zia/spark-scala/build.sbt
2023.10.23 19:23:24 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 19:23:24 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 19:24:27 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 19:24:27 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 19:24:33 WARN  no build target for: /home/zia/spark-scala/build.sbt
2023.10.23 19:24:33 INFO  skipping build import with status 'Dismissed'
2023.10.23 19:24:33 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 19:24:33 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 19:25:57 INFO  Shutting down server
2023.10.23 19:25:57 INFO  shutting down Metals
2023.10.23 19:26:26 INFO  Started: Metals version 1.1.0 in folders '/home/zia/spark-scala' for client Visual Studio Code 1.83.1.
2023.10.23 19:26:27 WARN  Build server is not auto-connectable.
2023.10.23 19:26:27 WARN  no build target for: /home/zia/spark-scala/build.sbt
2023.10.23 19:26:29 INFO  no build target found for /home/zia/spark-scala/build.sbt. Using presentation compiler with project's scala-library version: 3.3.1
2023.10.23 19:26:31 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 19:26:31 INFO  time: code lens generation in 3.88s
2023.10.23 19:26:31 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
Oct 23, 2023 8:55:03 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 7
Oct 23, 2023 8:55:03 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 8
2023.10.23 20:55:04 WARN  Could not find semantic tokens for: file:///home/zia/spark-scala/build.sbt
2023.10.23 21:11:24 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
Oct 23, 2023 9:11:30 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 13
2023.10.23 21:11:37 INFO  time: code lens generation in 7.45s
2023.10.23 21:11:37 INFO  time: code lens generation in 7.17s
2023.10.23 21:12:14 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
Oct 23, 2023 9:19:56 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 119
2023.10.23 21:20:04 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.23 21:20:25 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.23 21:20:26 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.23 21:20:26 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.23 21:20:31 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.23 21:22:48 INFO  Shutting down server
2023.10.23 21:22:48 INFO  shutting down Metals
2023.10.23 21:22:48 INFO  Exiting server
2023.10.23 21:23:27 INFO  Started: Metals version 1.1.0 in folders '/home/zia/spark-scala' for client Visual Studio Code 1.83.1.
2023.10.23 21:23:28 WARN  Build server is not auto-connectable.
2023.10.23 21:23:29 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.23 21:23:33 INFO  no build target found for /home/zia/spark-scala/src/main/scala/Main.scala. Using presentation compiler with project's scala-library version: 3.3.1
2023.10.23 21:23:38 INFO  time: code lens generation in 7.16s
2023.10.23 21:24:10 INFO  Shutting down server
2023.10.23 21:24:10 INFO  shutting down Metals
2023.10.23 21:24:10 INFO  Exiting server
2023.10.23 21:24:11 ERROR Unexpected error initializing server: 
org.eclipse.lsp4j.jsonrpc.ResponseErrorException: Request window/showMessageRequest failed with message: Canceled
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint.handleResponse(RemoteEndpoint.java:209)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint.consume(RemoteEndpoint.java:193)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at org.eclipse.lsp4j.jsonrpc.json.ConcurrentMessageProcessor.run(ConcurrentMessageProcessor.java:113)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023.10.23 21:26:00 INFO  Started: Metals version 1.1.0 in folders '/home/zia/spark-scala' for client Visual Studio Code 1.83.1.
2023.10.23 21:26:02 WARN  Build server is not auto-connectable.
2023.10.23 21:26:02 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.23 21:26:04 INFO  no build target found for /home/zia/spark-scala/src/main/scala/Main.scala. Using presentation compiler with project's scala-library version: 3.3.1
2023.10.23 21:26:07 INFO  time: code lens generation in 5.62s
2023.10.23 21:47:01 INFO  Started: Metals version 1.1.0 in folders '/home/zia/spark-scala' for client Visual Studio Code 1.83.1.
2023.10.23 21:47:06 WARN  Build server is not auto-connectable.
2023.10.23 21:47:06 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.23 21:47:09 INFO  no build target found for /home/zia/spark-scala/src/main/scala/Main.scala. Using presentation compiler with project's scala-library version: 3.3.1
2023.10.23 21:47:11 INFO  time: code lens generation in 5.45s
2023.10.23 21:58:01 INFO  Shutting down server
2023.10.23 21:58:01 INFO  shutting down Metals
2023.10.24 10:52:43 INFO  Started: Metals version 1.1.0 in folders '/home/zia/spark-scala' for client Visual Studio Code 1.83.1.
2023.10.24 10:52:46 WARN  Build server is not auto-connectable.
2023.10.24 10:52:47 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 10:52:54 INFO  no build target found for /home/zia/spark-scala/src/main/scala/Main.scala. Using presentation compiler with project's scala-library version: 3.3.1
Oct 24, 2023 10:52:56 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2
Oct 24, 2023 10:52:56 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3
Oct 24, 2023 10:52:56 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1
Oct 24, 2023 10:52:56 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 10
Oct 24, 2023 10:52:56 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 13
Oct 24, 2023 10:52:56 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 14
Oct 24, 2023 10:52:56 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 16
Oct 24, 2023 10:52:57 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 27
2023.10.24 10:53:07 INFO  time: code lens generation in 2.46s
2023.10.24 10:53:08 INFO  time: code lens generation in 10s
2023.10.24 10:53:08 INFO  time: code lens generation in 11s
2023.10.24 10:53:08 INFO  time: code lens generation in 15s
2023.10.24 10:53:08 INFO  time: code lens generation in 1.84s
2023.10.24 10:53:08 INFO  time: code lens generation in 11s
2023.10.24 10:53:08 INFO  time: code lens generation in 11s
Oct 24, 2023 10:53:11 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 46
Oct 24, 2023 10:53:28 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 100
Oct 24, 2023 10:53:29 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 107
Oct 24, 2023 10:53:31 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 118
2023.10.24 10:53:40 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
Oct 24, 2023 10:53:45 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 145
Oct 24, 2023 11:13:58 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 151
2023.10.24 13:23:23 WARN  no build target for: /home/zia/spark-scala/hw0/Main.scala
Oct 24, 2023 1:58:59 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 445
2023.10.24 14:07:04 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 14:08:18 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
Oct 24, 2023 4:37:12 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 872
2023.10.24 16:40:44 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 16:40:52 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 16:41:18 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 16:42:20 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
Oct 24, 2023 4:47:35 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1368
Oct 24, 2023 4:47:35 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1369
2023.10.24 16:48:23 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 16:49:29 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 16:51:03 WARN  Using indexes to guess the definition of countWordFrequency
2023.10.24 16:51:03 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 16:53:47 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 16:54:06 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
Oct 24, 2023 4:54:32 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1843
2023.10.24 16:54:39 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
Oct 24, 2023 4:55:57 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1891
2023.10.24 16:56:10 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
Oct 24, 2023 4:56:52 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2040
2023.10.24 17:01:01 ERROR Failed to tokenize input for semantic tokens for /home/zia/spark-scala/src/main/scala/Main.scala
scala.meta.tokenizers.TokenizeException: <input>:40: error: unclosed string literal
  val wordFrequencyDF = countWordFrequency("TselectedDF)
                                           ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023.10.24 17:01:01 ERROR Failed to tokenize input for semantic tokens for /home/zia/spark-scala/src/main/scala/Main.scala
scala.meta.tokenizers.TokenizeException: <input>:40: error: unclosed string literal
  val wordFrequencyDF = countWordFrequency("TileselectedDF)
                                           ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023.10.24 17:01:03 ERROR Failed to tokenize input for semantic tokens for /home/zia/spark-scala/src/main/scala/Main.scala
scala.meta.tokenizers.TokenizeException: <input>:40: error: unclosed string literal
  val wordFrequencyDF = countWordFrequency("TiselectedDF)
                                           ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023.10.24 17:01:03 ERROR Failed to tokenize input for semantic tokens for /home/zia/spark-scala/src/main/scala/Main.scala
scala.meta.tokenizers.TokenizeException: <input>:40: error: unclosed string literal
  val wordFrequencyDF = countWordFrequency("TitleselectedDF)
                                           ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Oct 24, 2023 5:04:05 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2363
2023.10.24 17:14:40 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 17:22:18 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
Oct 24, 2023 5:22:27 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2755
2023.10.24 17:27:58 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 17:32:31 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 17:34:24 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 17:37:20 ERROR Failed to tokenize input for semantic tokens for /home/zia/spark-scala/src/main/scala/Main.scala
scala.meta.tokenizers.TokenizeException: <input>:51: error: unclosed string interpolation
    .select("explode(col("words")).as("word"))
                                            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023.10.24 17:37:21 ERROR Failed to tokenize input for semantic tokens for /home/zia/spark-scala/src/main/scala/Main.scala
scala.meta.tokenizers.TokenizeException: <input>:51: error: unclosed string interpolation
    .select("Dexplode(col("words")).as("word"))
                                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023.10.24 17:37:22 ERROR Failed to tokenize input for semantic tokens for /home/zia/spark-scala/src/main/scala/Main.scala
scala.meta.tokenizers.TokenizeException: <input>:51: error: unclosed string interpolation
    .select("Datexplode(col("words")).as("word"))
                                               ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023.10.24 17:37:22 ERROR Failed to tokenize input for semantic tokens for /home/zia/spark-scala/src/main/scala/Main.scala
scala.meta.tokenizers.TokenizeException: <input>:51: error: unclosed string interpolation
    .select("Dateexplode(col("words")).as("word"))
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Oct 24, 2023 5:38:36 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3202
2023.10.24 17:38:53 WARN  Using indexes to guess the definition of selectedDF
2023.10.24 17:39:03 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
Oct 24, 2023 5:39:33 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3269
2023.10.24 17:39:35 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 17:39:35 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
Oct 24, 2023 5:39:35 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3276
2023.10.24 17:42:20 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 17:43:07 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 17:43:46 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 17:44:43 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 17:48:34 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 17:49:03 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 17:49:33 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 17:50:49 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 17:53:39 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
Oct 24, 2023 5:54:10 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3676
2023.10.24 17:54:40 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
Oct 24, 2023 6:04:58 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4118
2023.10.24 18:05:15 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 18:06:35 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 18:07:24 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 18:07:24 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
Oct 24, 2023 6:07:32 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4235
2023.10.24 18:07:48 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 18:08:57 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 18:08:57 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 18:08:57 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
Oct 24, 2023 6:09:54 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4354
2023.10.24 18:09:56 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 18:10:02 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 18:10:02 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 18:10:10 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 18:10:10 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 18:10:10 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 18:10:44 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
Oct 24, 2023 6:11:11 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4452
Oct 24, 2023 6:11:19 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4457
2023.10.24 18:12:41 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 18:16:28 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 18:17:38 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 18:21:31 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 18:22:17 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
Oct 24, 2023 6:53:42 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 5747
2023.10.24 18:54:14 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
Oct 24, 2023 7:45:46 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 5987
Oct 24, 2023 7:46:10 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 6053
Oct 24, 2023 7:46:34 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 6097
2023.10.24 19:46:50 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
Oct 24, 2023 7:51:46 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 6274
2023.10.24 19:51:49 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 19:53:37 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 19:56:05 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 19:56:57 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 19:57:00 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 19:58:08 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 19:58:54 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 19:59:51 ERROR Failed to tokenize input for semantic tokens for /home/zia/spark-scala/src/main/scala/Main.scala
scala.meta.tokenizers.TokenizeException: <input>:32: error: Non-zero integral values may not have a leading zero.
    .limit(00) // For function checking
           ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.restOfUncertainToken$1(LegacyScanner.scala:856)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:872)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:330)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:332)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023.10.24 19:59:52 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 20:02:12 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 20:02:49 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 20:06:00 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 20:11:53 ERROR Failed to tokenize input for semantic tokens for /home/zia/spark-scala/src/main/scala/Main.scala
scala.meta.tokenizers.TokenizeException: <input>:66: error: unclosed character literal
    .withColumn("coexists", coexists_space", expr("array_contains(array1, 'space') or array_contains(array1, 'Space') or array_contains(array2, 'space') or array_contains(array2, 'Space')"))
                                                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:407)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:412)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023.10.24 20:12:05 ERROR Failed to tokenize input for semantic tokens for /home/zia/spark-scala/src/main/scala/Main.scala
scala.meta.tokenizers.TokenizeException: <input>:66: error: unclosed character literal
    .withColumn("coexists", ", expr("array_contains(array1, 'space') or array_contains(array1, 'Space') or array_contains(array2, 'space') or array_contains(array2, 'Space')"))
                                                                  ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:407)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:412)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023.10.24 20:13:22 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 20:13:39 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 20:14:15 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 20:31:48 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 20:33:00 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 20:33:47 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 20:33:50 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 20:34:18 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 20:35:10 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 20:35:40 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 20:35:47 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 20:37:51 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 20:39:24 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 20:45:55 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 20:46:17 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 20:47:15 ERROR Failed to tokenize input for semantic tokens for /home/zia/spark-scala/src/main/scala/Main.scala
scala.meta.tokenizers.TokenizeException: <input>:72: error: unclosed string interpolation
    .withColumn("title", concat_ws(" col("words_title")))
                                                      ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023.10.24 20:47:19 ERROR Failed to tokenize input for semantic tokens for /home/zia/spark-scala/src/main/scala/Main.scala
scala.meta.tokenizers.TokenizeException: <input>:73: error: unclosed string literal
    .withColumn("postexcerpt", concat_ws(" col("words_postexcerpt"), " "))
                                                                       ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023.10.24 20:47:27 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 20:48:48 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 20:55:17 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 21:00:07 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 21:02:01 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 21:03:05 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
Oct 24, 2023 9:03:05 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 8539
2023.10.24 21:03:05 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
Oct 24, 2023 9:03:05 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 8540
2023.10.24 21:03:48 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 21:03:53 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 21:03:58 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 21:04:31 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 21:07:45 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 21:07:59 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 21:09:18 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
Oct 24, 2023 9:09:49 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 8734
2023.10.24 21:09:53 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
Oct 24, 2023 9:09:57 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 8753
2023.10.24 21:11:01 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 21:14:45 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 21:14:55 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 21:16:04 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
Oct 24, 2023 9:18:25 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 8995
2023.10.24 21:19:39 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 21:20:09 ERROR Failed to tokenize input for semantic tokens for /home/zia/spark-scala/src/main/scala/Main.scala
scala.meta.tokenizers.TokenizeException: <input>:86: error: unclosed string literal
      .groupBy("word)
               ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023.10.24 21:20:24 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 21:21:57 ERROR Failed to tokenize input for semantic tokens for /home/zia/spark-scala/src/main/scala/Main.scala
scala.meta.tokenizers.TokenizeException: <input>:82: error: unclosed string literal
    val newColumnName = "columnName
                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023.10.24 21:21:58 ERROR Failed to tokenize input for semantic tokens for /home/zia/spark-scala/src/main/scala/Main.scala
scala.meta.tokenizers.TokenizeException: <input>:82: error: unclosed string literal
    val newColumnName = "WcolumnName
                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023.10.24 21:21:59 ERROR Failed to tokenize input for semantic tokens for /home/zia/spark-scala/src/main/scala/Main.scala
scala.meta.tokenizers.TokenizeException: <input>:82: error: unclosed string literal
    val newColumnName = "columnName
                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023.10.24 21:22:00 ERROR Failed to tokenize input for semantic tokens for /home/zia/spark-scala/src/main/scala/Main.scala
scala.meta.tokenizers.TokenizeException: <input>:82: error: unclosed string literal
    val newColumnName = "worcolumnName
                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023.10.24 21:22:00 ERROR Failed to tokenize input for semantic tokens for /home/zia/spark-scala/src/main/scala/Main.scala
scala.meta.tokenizers.TokenizeException: <input>:82: error: unclosed string literal
    val newColumnName = "wordcolumnName
                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023.10.24 21:22:08 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 21:22:53 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
Oct 24, 2023 9:23:43 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 9463
2023.10.24 21:23:45 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 21:38:20 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 21:39:30 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 21:43:21 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 21:43:50 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 21:44:39 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 21:45:08 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 21:46:39 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 21:47:34 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 21:50:12 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
Oct 24, 2023 9:50:52 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 10397
2023.10.24 21:56:16 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 22:14:22 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 22:15:13 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 22:16:11 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
Oct 24, 2023 10:17:29 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 10659
2023.10.24 22:18:03 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 22:18:07 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 22:18:39 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 22:19:19 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 22:20:02 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 22:20:42 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 22:23:23 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
Oct 24, 2023 10:24:15 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 11009
2023.10.24 22:25:12 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 22:32:43 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
Oct 24, 2023 10:53:50 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 11221
2023.10.24 22:53:51 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 22:56:00 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 22:57:09 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 23:00:36 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 23:09:32 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 23:10:18 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 23:13:50 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 23:21:38 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 23:35:45 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.24 23:50:11 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 00:46:04 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 00:46:45 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 00:57:16 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 01:02:41 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 01:03:46 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 09:14:16 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 09:18:39 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 09:18:59 WARN  Using indexes to guess the definition of dataPath
2023.10.25 09:19:14 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 09:19:19 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 09:22:38 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 09:23:51 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 09:24:07 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 09:26:10 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 09:28:51 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
Oct 25, 2023 9:32:34 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 12144
2023.10.25 09:36:43 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 09:38:23 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 09:39:51 ERROR Failed to tokenize input for semantic tokens for /home/zia/spark-scala/src/main/scala/Main.scala
scala.meta.tokenizers.TokenizeException: <input>:31: error: unclosed string literal
    .option("quote", "\")
                     ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023.10.25 09:39:53 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 09:39:54 ERROR Failed to tokenize input for semantic tokens for /home/zia/spark-scala/src/main/scala/Main.scala
scala.meta.tokenizers.TokenizeException: <input>:31: error: unclosed multi-line string literal
    .option("quote", """)
                     ^
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:27)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:26)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getRawStringLit(LegacyScanner.scala:567)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:366)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023.10.25 09:39:56 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 09:42:26 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 09:46:08 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 09:46:36 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 09:47:16 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 09:56:43 ERROR Failed to tokenize input for semantic tokens for /home/zia/spark-scala/src/main/scala/Main.scala
scala.meta.tokenizers.TokenizeException: <input>:31: error: unclosed string literal
    .option("quote","\")
                    ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023.10.25 09:56:51 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 09:57:53 ERROR Failed to tokenize input for semantic tokens for /home/zia/spark-scala/src/main/scala/Main.scala
scala.meta.tokenizers.TokenizeException: <input>:32: error: unclosed string literal
    .option("escape", "\") 
                      ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023.10.25 09:57:54 ERROR Failed to tokenize input for semantic tokens for /home/zia/spark-scala/src/main/scala/Main.scala
scala.meta.tokenizers.TokenizeException: <input>:32: error: invalid escape character
    .option("escape", "\") 
                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023.10.25 09:57:58 ERROR Failed to tokenize input for semantic tokens for /home/zia/spark-scala/src/main/scala/Main.scala
scala.meta.tokenizers.TokenizeException: <input>:32: error: unclosed string literal
    .option("escape", "\") 
                      ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023.10.25 09:58:13 ERROR Failed to tokenize input for semantic tokens for /home/zia/spark-scala/src/main/scala/Main.scala
scala.meta.tokenizers.TokenizeException: <input>:32: error: unclosed string literal
    .option("escape", "\") 
                      ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023.10.25 09:58:25 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 10:05:23 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
Oct 25, 2023 10:07:15 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 12517
2023.10.25 10:07:17 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 10:07:21 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 10:09:05 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 10:09:07 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 10:09:18 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 10:10:41 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 10:11:04 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 10:13:46 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 10:14:58 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 10:16:38 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 10:24:45 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 10:25:34 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 10:26:13 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
Oct 25, 2023 10:29:48 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 12954
2023.10.25 10:30:07 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 10:31:02 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 10:32:00 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 10:38:28 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 17:32:46 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 17:32:59 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 17:33:26 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 17:38:42 ERROR Failed to tokenize input for semantic tokens for /home/zia/spark-scala/src/main/scala/Main.scala
scala.meta.tokenizers.TokenizeException: <input>:52: error: unclosed string interpolation
    .select("daavg("count").as("avg_articles_per_day"))
                                                     ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023.10.25 17:38:43 ERROR Failed to tokenize input for semantic tokens for /home/zia/spark-scala/src/main/scala/Main.scala
scala.meta.tokenizers.TokenizeException: <input>:52: error: unclosed string interpolation
    .select("dateavg("count").as("avg_articles_per_day"))
                                                       ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023.10.25 17:38:45 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 20:31:47 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 20:32:59 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
Oct 25, 2023 8:34:24 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 13318
2023.10.25 20:34:28 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 20:34:53 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 20:35:48 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 20:36:46 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 20:42:58 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
Oct 25, 2023 8:51:49 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 13513
2023.10.25 20:52:27 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 20:52:41 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 20:52:50 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 20:52:57 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 21:14:16 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 21:14:35 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 21:14:53 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 21:23:51 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 21:23:52 WARN  no build target for: /home/zia/spark-scala/hw0/Main.scala
Oct 25, 2023 9:24:28 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 13840
2023.10.25 21:25:05 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 21:27:14 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
Oct 25, 2023 9:30:46 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 14412
Oct 25, 2023 9:31:26 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 14558
2023.10.25 21:33:33 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
Oct 25, 2023 9:34:36 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 14993
2023.10.25 21:43:33 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 21:43:39 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 21:45:10 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 21:48:52 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 21:48:53 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 21:52:32 WARN  Using indexes to guess the definition of dataPath
2023.10.25 21:52:38 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.25 21:54:13 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.26 09:45:45 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.26 09:46:41 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.26 09:47:13 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.26 09:52:31 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.26 09:54:38 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.26 09:54:56 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.26 09:56:32 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.26 09:56:44 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.26 09:59:53 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.26 10:00:05 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
Oct 26, 2023 10:00:43 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 16442
2023.10.26 10:00:51 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.26 10:01:02 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.26 10:01:15 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.26 10:02:24 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
Oct 26, 2023 10:03:44 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 16589
Oct 26, 2023 10:07:06 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 16794
2023.10.26 10:09:15 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.26 10:10:00 WARN  Using indexes to guess the definition of total_count_distinct_dates
2023.10.26 10:10:00 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.26 10:10:10 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.26 10:10:39 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.26 10:13:54 ERROR Failed to tokenize input for semantic tokens for /home/zia/spark-scala/src/main/scala/Main.scala
scala.meta.tokenizers.TokenizeException: <input>:59: error: unclosed string literal
    .groupBy("author", "da)
                       ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Oct 26, 2023 10:15:11 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 17354
2023.10.26 10:15:18 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.26 10:17:27 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.26 12:40:34 ERROR Failed to tokenize input for semantic tokens for /home/zia/spark-scala/src/main/scala/Main.scala
scala.meta.tokenizers.TokenizeException: <input>:60: error: unclosed string interpolation
    .groupBy("da"author")
                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023.10.26 12:40:34 ERROR Failed to tokenize input for semantic tokens for /home/zia/spark-scala/src/main/scala/Main.scala
scala.meta.tokenizers.TokenizeException: <input>:60: error: unclosed string interpolation
    .groupBy("date"author")
                          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Oct 26, 2023 1:00:24 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 17830
2023.10.26 14:11:59 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
Oct 26, 2023 2:14:11 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 18407
Oct 26, 2023 2:14:26 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 18420
2023.10.26 14:14:35 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.26 14:14:47 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
Oct 26, 2023 2:16:32 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 18552
Oct 26, 2023 2:16:32 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 18553
2023.10.26 14:17:22 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.26 14:18:10 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.26 14:19:29 ERROR Failed to tokenize input for semantic tokens for /home/zia/spark-scala/src/main/scala/Main.scala
scala.meta.tokenizers.TokenizeException: <input>:64: error: unclosed string interpolation
    .select("date", "au"total_articles_each_author_per_day")
                                                           ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023.10.26 14:19:29 ERROR Failed to tokenize input for semantic tokens for /home/zia/spark-scala/src/main/scala/Main.scala
scala.meta.tokenizers.TokenizeException: <input>:64: error: unclosed string interpolation
    .select("date", "author"total_articles_each_author_per_day")
                                                               ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023.10.26 14:19:35 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.26 14:21:10 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.26 14:21:12 WARN  Using indexes to guess the definition of groupedByDateAuthor
2023.10.26 14:21:12 WARN  Using indexes to guess the definition of groupedByDateAuthor
2023.10.26 14:21:12 WARN  Using indexes to guess the definition of groupedByDateAuthor
Oct 26, 2023 2:21:56 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 18967
2023.10.26 14:22:05 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.26 14:24:27 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.26 14:25:48 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.26 14:28:28 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.26 14:28:57 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.26 14:33:48 WARN  Using indexes to guess the definition of columnsToAnalyze
2023.10.26 14:33:48 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
2023.10.26 14:34:02 WARN  no build target for: /home/zia/spark-scala/src/main/scala/Main.scala
